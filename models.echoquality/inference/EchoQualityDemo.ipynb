{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EchoQuality Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the EchoQuality model to assess the quality of echocardiogram videos. The model analyzes DICOM files and predicts whether the video quality is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The EchoQuality model uses a pre-trained R(2+1)D model to classify the quality of echocardiogram videos. The model processes DICOM files, applies masking to isolate the ultrasound region, and classifies videos as PASS/FAIL with a threshold of 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.video import r2plus1d_18\n",
    "import json\n",
    "\n",
    "# Import functions from our modules\n",
    "from inference.EchoPrime_qc import mask_outside_ultrasound, crop_and_scale, get_quality_issues\n",
    "from training.echo_model_evaluation import visualize_gradcam\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "Now, let's load the pre-trained EchoQuality model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Constants for video processing\n",
    "frames_to_take = 32\n",
    "frame_stride = 2\n",
    "video_size = 112\n",
    "mean = torch.tensor([29.110628, 28.076836, 29.096405]).reshape(3, 1, 1, 1)\n",
    "std = torch.tensor([47.989223, 46.456997, 47.20083]).reshape(3, 1, 1, 1)\n",
    "\n",
    "# Load model\n",
    "model_weights = \"./weights/video_quality_model.pt\"\n",
    "model = r2plus1d_18(num_classes=1)\n",
    "model.load_state_dict(torch.load(model_weights, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded from {model_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a DICOM File\n",
    "\n",
    "Let's define a function to process a DICOM file and prepare it for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_dicom(dicom_path, save_mask_images=False):\n",
    "    \"\"\"\n",
    "    Process a single DICOM file and prepare it for the model.\n",
    "    \n",
    "    Args:\n",
    "        dicom_path (str): Path to the DICOM file\n",
    "        save_mask_images (bool): Whether to save mask images\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Processed video tensor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read DICOM file\n",
    "        dcm = pydicom.dcmread(dicom_path)\n",
    "        pixels = dcm.pixel_array\n",
    "        \n",
    "        # Print DICOM info\n",
    "        print(f\"DICOM shape: {pixels.shape}\")\n",
    "        print(f\"DICOM dimensions: {pixels.ndim}\")\n",
    "        \n",
    "        # Handle different dimensions\n",
    "        if pixels.ndim < 3 or pixels.shape[2] == 3:\n",
    "            print(f\"Skipping {dicom_path}: Invalid dimensions {pixels.shape}\")\n",
    "            return None\n",
    "        \n",
    "        # If single channel, repeat to 3 channels\n",
    "        if pixels.ndim == 3:\n",
    "            pixels = np.repeat(pixels[..., None], 3, axis=3)\n",
    "        \n",
    "        # Mask everything outside ultrasound region\n",
    "        filename = os.path.basename(dicom_path)\n",
    "        pixels = mask_outside_ultrasound(pixels, filename if save_mask_images else None)\n",
    "        \n",
    "        # Model specific preprocessing\n",
    "        x = np.zeros((len(pixels), video_size, video_size, 3))\n",
    "        for i in range(len(x)):\n",
    "            x[i] = crop_and_scale(pixels[i])\n",
    "        \n",
    "        # Convert to tensor and permute dimensions\n",
    "        x = torch.as_tensor(x, dtype=torch.float).permute([3, 0, 1, 2])\n",
    "        \n",
    "        # Normalize\n",
    "        x.sub_(mean).div_(std)\n",
    "        \n",
    "        # If not enough frames, add padding\n",
    "        if x.shape[1] < frames_to_take:\n",
    "            padding = torch.zeros(\n",
    "                (\n",
    "                    3,\n",
    "                    frames_to_take - x.shape[1],\n",
    "                    video_size,\n",
    "                    video_size,\n",
    "                ),\n",
    "                dtype=torch.float,\n",
    "            )\n",
    "            x = torch.cat((x, padding), dim=1)\n",
    "        \n",
    "        # Apply stride and take required frames\n",
    "        start = 0\n",
    "        x = x[:, start: (start + frames_to_take): frame_stride, :, :]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dicom_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find DICOM Files\n",
    "\n",
    "Let's find DICOM files in the example directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Path to example DICOM files\n",
    "example_dir = \"./data/example_study\"\n",
    "\n",
    "# Find DICOM files\n",
    "dicom_paths = glob.glob(f\"{example_dir}/**/*\", recursive=True)\n",
    "print(f\"Found {len(dicom_paths)} DICOM files\")\n",
    "\n",
    "# Display the first few paths\n",
    "for path in dicom_paths[:5]:\n",
    "    print(f\"- {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Analyze a Single DICOM File\n",
    "\n",
    "Let's process and analyze a single DICOM file to see how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process the first DICOM file\n",
    "if len(dicom_paths) > 0:\n",
    "    dicom_path = dicom_paths[0]\n",
    "    print(f\"Processing {dicom_path}...\")\n",
    "    \n",
    "    # Process DICOM file\n",
    "    video = process_dicom(dicom_path, save_mask_images=True)\n",
    "    \n",
    "    if video is not None:\n",
    "        print(f\"Processed video shape: {video.shape}\")\n",
    "        \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            video_tensor = video.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            output = model(video_tensor)\n",
    "            probability = torch.sigmoid(output).item()\n",
    "            prediction = 1 if probability >= 0.3 else 0\n",
    "            status = \"PASS\" if prediction > 0 else \"FAIL\"\n",
    "            assessment = get_quality_issues(probability)\n",
    "        \n",
    "        print(f\"\\nQuality Assessment Results:\")\n",
    "        print(f\"Score: {probability:.4f}\")\n",
    "        print(f\"Status: {status}\")\n",
    "        print(f\"Assessment: {assessment}\")\n",
    "        \n",
    "        # Visualize the first frame\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        frame = video.permute(1, 2, 3, 0)[0].cpu().numpy()  # Get first frame\n",
    "        frame = (frame - frame.min()) / (frame.max() - frame.min())  # Normalize for display\n",
    "        plt.imshow(frame)\n",
    "        plt.title(f\"First Frame - Quality Score: {probability:.4f} ({status})\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Generate GradCAM visualization\n",
    "        print(\"\\nGenerating GradCAM visualization...\")\n",
    "        visualize_gradcam(\n",
    "            model, \n",
    "            video, \n",
    "            target_layer_name=\"layer4\", \n",
    "            save_path=\"./results/gradcam_visualization.png\"\n",
    "        )\n",
    "        \n",
    "        # Display GradCAM visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        img = plt.imread(\"./results/gradcam_visualization.png\")\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"GradCAM Visualization\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to process DICOM file.\")\n",
    "else:\n",
    "    print(\"No DICOM files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Multiple DICOM Files\n",
    "\n",
    "Now, let's process all DICOM files in the example directory and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process all DICOM files\n",
    "results = {}\n",
    "\n",
    "for dicom_path in tqdm(dicom_paths, desc=\"Processing\"):\n",
    "    filename = os.path.basename(dicom_path)\n",
    "    \n",
    "    # Process DICOM file\n",
    "    video = process_dicom(dicom_path)\n",
    "    \n",
    "    if video is None:\n",
    "        print(f\"Skipping {filename}: Processing failed\")\n",
    "        continue\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        video_tensor = video.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        output = model(video_tensor)\n",
    "        probability = torch.sigmoid(output).item()\n",
    "        prediction = 1 if probability >= 0.3 else 0\n",
    "        status = \"PASS\" if prediction > 0 else \"FAIL\"\n",
    "        assessment = get_quality_issues(probability)\n",
    "    \n",
    "    # Store results\n",
    "    results[filename] = {\n",
    "        \"score\": probability,\n",
    "        \"status\": status,\n",
    "        \"assessment\": assessment\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "print(\"\\nQuality Assessment Results:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Filename':<60} {'Score':<10} {'Pass/Fail':<10} {'Assessment'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for filename, result in results.items():\n",
    "    # Truncate filename if too long\n",
    "    short_filename = filename[:57] + \"...\" if len(filename) > 60 else filename.ljust(60)\n",
    "    print(f\"{short_filename} {result['score']:.4f}    {result['status']:<10} {result['assessment']}\")\n",
    "\n",
    "# Summary statistics\n",
    "pass_count = sum(1 for result in results.values() if result[\"status\"] == \"PASS\")\n",
    "total_count = len(results)\n",
    "pass_rate = pass_count/total_count*100 if total_count > 0 else 0\n",
    "\n",
    "print(f\"\\nSummary: {pass_count}/{total_count} videos passed quality check ({pass_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's create some visualizations of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract scores\n",
    "scores = [result[\"score\"] for result in results.values()]\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(scores, bins=20, alpha=0.7, color='blue')\n",
    "plt.axvline(x=0.3, color='red', linestyle='--', label='Threshold (0.3)')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Echo Quality Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create pie chart of pass/fail\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    [pass_count, total_count - pass_count], \n",
    "    labels=[\"PASS\", \"FAIL\"], \n",
    "    autopct='%1.1f%%',\n",
    "    colors=['#4CAF50', '#F44336'],\n",
    "    explode=(0.1, 0)\n",
    ")\n",
    "plt.title('Pass/Fail Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Finally, let's save the results to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save results to JSON\n",
    "with open(\"./results/quality_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to ./results/quality_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the EchoQuality model to assess the quality of echocardiogram videos. The model processes DICOM files, applies masking to isolate the ultrasound region, and classifies videos as PASS/FAIL with a threshold of 0.3.\n",
    "\n",
    "The model can be used to automatically filter out low-quality echocardiogram videos, which can help improve the accuracy of downstream analysis and reduce the time spent on manual quality control."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
